{
  "id": "4B62DBE6307E424AA63CBF016DD7F425",
  "device": {
    "os": "Linux-6.14.0-37-generic-x86_64-with-glibc2.39",
    "python_version": "3.13.8",
    "processor": "Intel(R) Core(TM) Ultra 7 265K",
    "accelerator": {
      "type": "cuda",
      "count": 1,
      "devices": [
        {
          "name": "NVIDIA GeForce RTX 5070 Ti",
          "total_memory_gb": 15.47,
          "compute_capability": "12.0"
        }
      ]
    },
    "cpu_cores_physical": 20,
    "cpu_cores_logical": 20,
    "cpu_frequency_mhz": 5120.0,
    "total_memory_gb": 30.62,
    "torch_num_threads": 20
  },
  "config": {
    "seed": 1,
    "dataset": "NewsHeadlinesDataset",
    "pretrained_model_name": "prajjwal1/bert-small",
    "classification_head": {
      "head_type": "BertSingleTokenAttention",
      "dropout_p": 0.1
    },
    "train_test_split": 0.7,
    "batch_size": 16,
    "learning_rate": 0.0001,
    "max_grad_norm": 1.0,
    "num_train_epochs": 5
  },
  "metadata": {
    "created_time": "2025-12-24T16:07:01.628271+01:00",
    "updated_time": "2025-12-24T16:12:13.182404+01:00",
    "num_params": 28765186,
    "best_epoch": 1,
    "best_valid_f1": 0.9070576786435653
  },
  "results": {
    "train": [
      {
        "epoch": 0,
        "loss": 0.31927913949503034,
        "accuracy": 0.8665701592372586,
        "precision": 0.8662125465662931,
        "recall": 0.8663146260281487,
        "f1": 0.8662617596652431,
        "train_time_taken": 57.82144643799984
      },
      {
        "epoch": 1,
        "loss": 0.17065478682411903,
        "accuracy": 0.9425448010782209,
        "precision": 0.9424416564012302,
        "recall": 0.94235682374474,
        "f1": 0.9423983861303925,
        "train_time_taken": 57.73027529800311
      },
      {
        "epoch": 2,
        "loss": 0.09186667469600499,
        "accuracy": 0.9749912644137174,
        "precision": 0.9750397978242937,
        "recall": 0.9748185218063986,
        "f1": 0.9749242015183329,
        "train_time_taken": 57.72736252199684
      },
      {
        "epoch": 3,
        "loss": 0.06073057659055879,
        "accuracy": 0.9844256975989617,
        "precision": 0.984472023770698,
        "recall": 0.9843033282432473,
        "f1": 0.9843848183612169,
        "train_time_taken": 57.731125478996546
      },
      {
        "epoch": 4,
        "loss": 0.04703320749847297,
        "accuracy": 0.989018120101832,
        "precision": 0.9889817931494764,
        "recall": 0.9890010818031502,
        "f1": 0.9889913977607221,
        "train_time_taken": 57.716357731987955
      }
    ],
    "valid": [
      {
        "epoch": 0,
        "loss": 0.24640420433064597,
        "accuracy": 0.8951781970649895,
        "precision": 0.8973063940062806,
        "recall": 0.8961415777684829,
        "f1": 0.8951461944882998,
        "evaluate_time_taken": 3.785190976996091
      },
      {
        "epoch": 1,
        "loss": 0.28055859479333056,
        "accuracy": 0.907058001397624,
        "precision": 0.9077265920645587,
        "recall": 0.9076465468153667,
        "f1": 0.9070576786435653,
        "evaluate_time_taken": 3.7877201180090196
      },
      {
        "epoch": 2,
        "loss": 0.3993694732665884,
        "accuracy": 0.8979734451432565,
        "precision": 0.8994751117585011,
        "recall": 0.8972510948581733,
        "f1": 0.897702345812591,
        "evaluate_time_taken": 3.7827416630025255
      },
      {
        "epoch": 3,
        "loss": 0.5977323048916424,
        "accuracy": 0.8996040065222455,
        "precision": 0.9001424846667735,
        "recall": 0.9001424846667735,
        "f1": 0.8996040065222455,
        "evaluate_time_taken": 3.7849143100029323
      },
      {
        "epoch": 4,
        "loss": 0.6772435952435245,
        "accuracy": 0.8984393198229677,
        "precision": 0.8991841929869229,
        "recall": 0.8990512097840775,
        "f1": 0.898438388512443,
        "evaluate_time_taken": 3.7857337909954367
      }
    ],
    "test": [
      {
        "epoch": null,
        "loss": 0.26293336235672293,
        "accuracy": 0.9077568134171907,
        "precision": 0.9075417676327869,
        "recall": 0.9089575810800039,
        "f1": 0.9076514610601959,
        "evaluate_time_taken": 3.789187590009533
      }
    ]
  }
}
{
  "id": "E23B956E563B4D6C96702986E087E677",
  "device": {
    "os": "Linux-6.14.0-37-generic-x86_64-with-glibc2.39",
    "python_version": "3.13.8",
    "processor": "Intel(R) Core(TM) Ultra 7 265K",
    "accelerator": {
      "type": "cuda",
      "count": 1,
      "devices": [
        {
          "name": "NVIDIA GeForce RTX 5070 Ti",
          "total_memory_gb": 15.47,
          "compute_capability": "12.0"
        }
      ]
    },
    "cpu_cores_physical": 20,
    "cpu_cores_logical": 20,
    "cpu_frequency_mhz": 5120.0,
    "total_memory_gb": 30.62,
    "torch_num_threads": 20
  },
  "config": {
    "seed": 1,
    "dataset": "NewsHeadlinesDataset",
    "pretrained_model_name": "prajjwal1/bert-tiny",
    "classification_head": {
      "head_type": "BertSingleTokenAttention",
      "dropout_p": 0.1
    },
    "train_test_split": 0.7,
    "batch_size": 16,
    "learning_rate": 1e-05,
    "max_grad_norm": 1.0,
    "num_train_epochs": 5
  },
  "metadata": {
    "created_time": "2025-12-24T11:45:27.121871+01:00",
    "updated_time": "2025-12-24T11:46:11.017479+01:00",
    "num_params": 4386306,
    "best_epoch": 4,
    "best_valid_f1": 0.8805508726686306
  },
  "results": {
    "train": [
      {
        "epoch": 0,
        "loss": 0.5281656350455851,
        "accuracy": 0.7266510258074178,
        "precision": 0.726033443328139,
        "recall": 0.7258921911528442,
        "f1": 0.7259558239442457,
        "train_time_taken": 8.441115732988692
      },
      {
        "epoch": 1,
        "loss": 0.4001357592196343,
        "accuracy": 0.8170019467878001,
        "precision": 0.8165612404202452,
        "recall": 0.8168569748068224,
        "f1": 0.8166834664646937,
        "train_time_taken": 8.237907301998348
      },
      {
        "epoch": 2,
        "loss": 0.35552337840615705,
        "accuracy": 0.8416113412868766,
        "precision": 0.8412184944007796,
        "recall": 0.8413914111302141,
        "f1": 0.8412981063899971,
        "train_time_taken": 8.123038499004906
      },
      {
        "epoch": 3,
        "loss": 0.3249992982433114,
        "accuracy": 0.8588828433085409,
        "precision": 0.8585109402955012,
        "recall": 0.8587394350812094,
        "f1": 0.8586137281717106,
        "train_time_taken": 8.130614977999358
      },
      {
        "epoch": 4,
        "loss": 0.3010011570036102,
        "accuracy": 0.872160934458144,
        "precision": 0.8718406290741996,
        "recall": 0.8719526648084377,
        "f1": 0.8718942676436634,
        "train_time_taken": 8.143860070005758
      }
    ],
    "valid": [
      {
        "epoch": 0,
        "loss": 0.40830313256460493,
        "accuracy": 0.8150477521546704,
        "precision": 0.8156067764080608,
        "recall": 0.8163284424320287,
        "f1": 0.8149971494953977,
        "evaluate_time_taken": 0.4077350529987598
      },
      {
        "epoch": 1,
        "loss": 0.3566583893556134,
        "accuracy": 0.8471931050547403,
        "precision": 0.8474301794626738,
        "recall": 0.8460080923134772,
        "f1": 0.8465166652278666,
        "evaluate_time_taken": 0.4102271019946784
      },
      {
        "epoch": 2,
        "loss": 0.3303723773437805,
        "accuracy": 0.861169345446075,
        "precision": 0.8613581371281622,
        "recall": 0.8622844399878837,
        "f1": 0.8611013274976189,
        "evaluate_time_taken": 0.4051993650064105
      },
      {
        "epoch": 3,
        "loss": 0.3157167645192058,
        "accuracy": 0.8709527137200093,
        "precision": 0.8705880053934693,
        "recall": 0.8714023282048068,
        "f1": 0.8707885935574723,
        "evaluate_time_taken": 0.40519430198764894
      },
      {
        "epoch": 4,
        "loss": 0.3043634072777064,
        "accuracy": 0.8809690193337992,
        "precision": 0.8809784715502742,
        "recall": 0.8802414637712949,
        "f1": 0.8805508726686306,
        "evaluate_time_taken": 0.4051125769910868
      }
    ],
    "test": [
      {
        "epoch": null,
        "loss": 0.3158987060701648,
        "accuracy": 0.8676915909620312,
        "precision": 0.8677408792897923,
        "recall": 0.8670632754833432,
        "f1": 0.8673336191493853,
        "evaluate_time_taken": 0.4063566480035661
      }
    ]
  }
}
{
  "id": "690B80796A01413B856A1DBC3B07A85C",
  "device": {
    "os": "Linux-6.14.0-37-generic-x86_64-with-glibc2.39",
    "python_version": "3.13.11",
    "processor": "Intel(R) Core(TM) Ultra 7 265K",
    "accelerator": {
      "type": "cuda",
      "count": 1,
      "devices": [
        {
          "name": "NVIDIA GeForce RTX 5070 Ti",
          "total_memory_gb": 15.47,
          "compute_capability": "12.0"
        }
      ]
    },
    "cpu_cores_physical": 20,
    "cpu_cores_logical": 20,
    "cpu_frequency_mhz": 5120.0,
    "total_memory_gb": 30.62,
    "torch_num_threads": 20
  },
  "config": {
    "seed": 8,
    "dataset": "NewsHeadlinesDataset",
    "pretrained_model_name": "google-bert/bert-base-uncased",
    "classification_head": {
      "head_type": "BertSingleTokenAttention",
      "dropout_p": 0.1
    },
    "train_test_split": 0.7,
    "batch_size": 32,
    "learning_rate": 2e-05,
    "max_grad_norm": 1.0,
    "num_train_epochs": 5
  },
  "metadata": {
    "created_time": "2025-12-27T23:14:31.133679+01:00",
    "updated_time": "2025-12-27T23:41:54.561515+01:00",
    "num_params": 109484546,
    "best_epoch": 4,
    "best_valid_f1": 0.926586481341589
  },
  "results": {
    "train": [
      {
        "epoch": 0,
        "loss": 0.2684160838040272,
        "accuracy": 0.8851894374282434,
        "precision": 0.884893735597962,
        "recall": 0.8849937528290089,
        "f1": 0.8849420052109928,
        "train_time_taken": 301.97177506200023
      },
      {
        "epoch": 1,
        "loss": 0.1160135696121481,
        "accuracy": 0.9588678680177707,
        "precision": 0.9587818436882308,
        "recall": 0.9587642259626772,
        "f1": 0.9587729963434743,
        "train_time_taken": 302.01088513099967
      },
      {
        "epoch": 2,
        "loss": 0.05598664819710852,
        "accuracy": 0.9835770977886488,
        "precision": 0.9835646805892841,
        "recall": 0.9835132427337864,
        "f1": 0.9835386630584312,
        "train_time_taken": 301.9949402409984
      },
      {
        "epoch": 3,
        "loss": 0.03507203551672744,
        "accuracy": 0.9905156491788549,
        "precision": 0.9905419088811079,
        "recall": 0.9904461540013811,
        "f1": 0.9904930371807276,
        "train_time_taken": 301.9922657709976
      },
      {
        "epoch": 4,
        "loss": 0.025767243652384687,
        "accuracy": 0.9934607896969999,
        "precision": 0.9934575934223474,
        "recall": 0.9934338821340101,
        "f1": 0.9934456754643273,
        "train_time_taken": 301.9572138779986
      }
    ],
    "valid": [
      {
        "epoch": 0,
        "loss": 0.2252998708712834,
        "accuracy": 0.9061262520382017,
        "precision": 0.9110512141294014,
        "recall": 0.9042177210788256,
        "f1": 0.9054389419527104,
        "evaluate_time_taken": 22.0128379279995
      },
      {
        "epoch": 1,
        "loss": 0.24575183190474356,
        "accuracy": 0.9219659911483811,
        "precision": 0.9223396721869501,
        "recall": 0.9228083367743898,
        "f1": 0.9219570307427398,
        "evaluate_time_taken": 22.006861113000923
      },
      {
        "epoch": 2,
        "loss": 0.3547020247516533,
        "accuracy": 0.9217330538085255,
        "precision": 0.9218020942803824,
        "recall": 0.9223618325255907,
        "f1": 0.9217116400887325,
        "evaluate_time_taken": 21.99574500399831
      },
      {
        "epoch": 3,
        "loss": 0.415906756098546,
        "accuracy": 0.9249941765665036,
        "precision": 0.9252199913175603,
        "recall": 0.9257467454849717,
        "f1": 0.9249809514506202,
        "evaluate_time_taken": 21.99401011399823
      },
      {
        "epoch": 4,
        "loss": 0.3689170694733211,
        "accuracy": 0.9266247379454927,
        "precision": 0.9264938197323165,
        "recall": 0.927029752461261,
        "f1": 0.926586481341589,
        "evaluate_time_taken": 21.98954783999943
      }
    ],
    "test": [
      {
        "epoch": null,
        "loss": 0.36120220889656424,
        "accuracy": 0.9315164220824598,
        "precision": 0.9311468742863978,
        "recall": 0.9315908408114215,
        "f1": 0.9313442224449325,
        "evaluate_time_taken": 21.99315913600003
      }
    ]
  }
}
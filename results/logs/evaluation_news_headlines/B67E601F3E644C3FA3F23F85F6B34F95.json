{
  "id": "B67E601F3E644C3FA3F23F85F6B34F95",
  "device": {
    "os": "Linux-6.14.0-37-generic-x86_64-with-glibc2.39",
    "python_version": "3.13.11",
    "processor": "Intel(R) Core(TM) Ultra 7 265K",
    "accelerator": {
      "type": "cuda",
      "count": 1,
      "devices": [
        {
          "name": "NVIDIA GeForce RTX 5070 Ti",
          "total_memory_gb": 15.47,
          "compute_capability": "12.0"
        }
      ]
    },
    "cpu_cores_physical": 20,
    "cpu_cores_logical": 20,
    "cpu_frequency_mhz": 5120.0,
    "total_memory_gb": 30.62,
    "torch_num_threads": 20
  },
  "config": {
    "seed": 3,
    "dataset": "NewsHeadlinesDataset",
    "pretrained_model_name": "prajjwal1/bert-tiny",
    "classification_head": {
      "head_type": "BertSingleTokenAttention",
      "dropout_p": 0.1
    },
    "train_test_split": 0.7,
    "batch_size": 16,
    "learning_rate": 0.0001,
    "max_grad_norm": 1.0,
    "num_train_epochs": 5
  },
  "metadata": {
    "created_time": "2025-12-28T07:35:29.414850+01:00",
    "updated_time": "2025-12-28T07:36:12.296156+01:00",
    "num_params": 4386306,
    "best_epoch": 2,
    "best_valid_f1": 0.8843347420339609
  },
  "results": {
    "train": [
      {
        "epoch": 0,
        "loss": 0.39473973725552997,
        "accuracy": 0.8162032646133879,
        "precision": 0.8159027992140544,
        "recall": 0.8156417536064732,
        "f1": 0.8157578448488124,
        "train_time_taken": 8.303366031999758
      },
      {
        "epoch": 1,
        "loss": 0.24010637637446297,
        "accuracy": 0.9021614336345031,
        "precision": 0.9019714721697196,
        "recall": 0.901949624698841,
        "f1": 0.9019604670619941,
        "train_time_taken": 8.005738087005739
      },
      {
        "epoch": 2,
        "loss": 0.1601225868795076,
        "accuracy": 0.9424449658064195,
        "precision": 0.9423984132855514,
        "recall": 0.9422450697323155,
        "f1": 0.942318506676304,
        "train_time_taken": 7.997821805998683
      },
      {
        "epoch": 3,
        "loss": 0.1186354411486973,
        "accuracy": 0.961563420356412,
        "precision": 0.9616516975254412,
        "recall": 0.9613190393726898,
        "f1": 0.9614721579461966,
        "train_time_taken": 7.930353586998535
      },
      {
        "epoch": 4,
        "loss": 0.08994948341513652,
        "accuracy": 0.9739429940598013,
        "precision": 0.9740653086878908,
        "recall": 0.9737237055036786,
        "f1": 0.973881125257032,
        "train_time_taken": 8.00742682100099
      }
    ],
    "valid": [
      {
        "epoch": 0,
        "loss": 0.306469010071462,
        "accuracy": 0.870020964360587,
        "precision": 0.8713171633603243,
        "recall": 0.872171024408727,
        "f1": 0.8699996266312633,
        "evaluate_time_taken": 0.3979930159985088
      },
      {
        "epoch": 1,
        "loss": 0.3133676140205623,
        "accuracy": 0.8770090845562544,
        "precision": 0.8824646981079578,
        "recall": 0.8735616402559987,
        "f1": 0.8754976897878296,
        "evaluate_time_taken": 0.39603400100168074
      },
      {
        "epoch": 2,
        "loss": 0.38509455917456764,
        "accuracy": 0.8844630794316329,
        "precision": 0.8842334475487955,
        "recall": 0.8854777982714205,
        "f1": 0.8843347420339609,
        "evaluate_time_taken": 0.39682726099999854
      },
      {
        "epoch": 3,
        "loss": 0.5370456404041856,
        "accuracy": 0.8735150244584207,
        "precision": 0.8743775260520494,
        "recall": 0.8754212024275894,
        "f1": 0.8734774312265606,
        "evaluate_time_taken": 0.3978217339972616
      },
      {
        "epoch": 4,
        "loss": 0.6573361601108124,
        "accuracy": 0.8798043326345213,
        "precision": 0.8818108692078255,
        "recall": 0.8823365002907098,
        "f1": 0.8797988475559835,
        "evaluate_time_taken": 0.3974020930036204
      }
    ],
    "test": [
      {
        "epoch": null,
        "loss": 0.392430801691529,
        "accuracy": 0.8851618914511996,
        "precision": 0.8848813096577883,
        "recall": 0.8856441803200237,
        "f1": 0.8850465253694283,
        "evaluate_time_taken": 0.40040640399820404
      }
    ]
  }
}